{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîÑüìà An√°lisis de Correlaci√≥n de Ciclos\n",
    "## Detecci√≥n y Sincronizaci√≥n de Ciclos Solares-Econ√≥micos\n",
    "\n",
    "**Autor:** Benjamin Cabeza Dur√°n (mechmind-dwv)  \n",
    "**Asistente:** DeepSeek AI  \n",
    "**Fecha:** Generado autom√°ticamente\n",
    "\n",
    "---\n",
    "\n",
    "Este notebook se especializa en el an√°lisis avanzado de correlaci√≥n entre ciclos solares y econ√≥micos, implementando m√©todos espectrales y de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n avanzada\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# An√°lisis avanzado\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftfreq\n",
    "import pywt  # Wavelets\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# Configuraci√≥n\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ M√≥dulos avanzados importados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. An√°lisis Espectral Cruzado Avanzado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.services.correlation_service import correlation_service\n",
    "\n",
    "# Cargar datos\n",
    "from app.services.nasa_solar_service import NASASolarService\n",
    "from app.services.economic_data_service import EconomicDataService\n",
    "\n",
    "nasa_service = NASASolarService()\n",
    "economic_service = EconomicDataService()\n",
    "\n",
    "# Obtener series temporales\n",
    "solar_data = await nasa_service.get_historical_solar_data(50)\n",
    "market_data = await economic_service.get_market_data(\"^GSPC\", \"50y\")\n",
    "\n",
    "# Preparar series\n",
    "sp500_prices = [item['price'] for item in market_data['market_data']]\n",
    "sp500_dates = [item['timestamp'] for item in market_data['market_data']]\n",
    "sp500_series = pd.Series(sp500_prices, index=pd.to_datetime(sp500_dates))\n",
    "\n",
    "sunspots_series = solar_data['sunspots'] if 'sunspots' in solar_data.columns else solar_data.iloc[:, 0]\n",
    "\n",
    "# An√°lisis espectral cruzado\n",
    "print(\"üîç Realizando an√°lisis espectral cruzado...\")\n",
    "spectral_analysis = await correlation_service.cross_spectral_analysis(sunspots_series, sp500_series)\n",
    "\n",
    "# Visualizar resultados\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Per√≠odos comunes\n",
    "periods = list(spectral_analysis.coherence_spectrum.keys())\n",
    "coherence = list(spectral_analysis.coherence_spectrum.values())\n",
    "\n",
    "axes[0, 0].bar(periods[:10], coherence[:10], color='skyblue', alpha=0.7)\n",
    "axes[0, 0].set_title('Coherencia Espectral - Top 10 Per√≠odos', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Per√≠odo (a√±os)')\n",
    "axes[0, 0].set_ylabel('Coherencia')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Sincronizaci√≥n de fase\n",
    "phase_periods = list(spectral_analysis.phase_synchronization.keys())\n",
    "phase_sync = list(spectral_analysis.phase_synchronization.values())\n",
    "\n",
    "axes[0, 1].scatter(phase_periods, phase_sync, alpha=0.6, color='coral')\n",
    "axes[0, 1].set_title('Sincronizaci√≥n de Fase', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Per√≠odo (a√±os)')\n",
    "axes[0, 1].set_ylabel('Sincronizaci√≥n')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Ciclos compartidos\n",
    "shared_cycles = spectral_analysis.shared_cycles\n",
    "cycle_names = [cycle['cycle_type'] for cycle in shared_cycles[:5]]\n",
    "cycle_strengths = [cycle['coherence_strength'] for cycle in shared_cycles[:5]]\n",
    "\n",
    "axes[1, 0].barh(cycle_names, cycle_strengths, color='lightgreen')\n",
    "axes[1, 0].set_title('Ciclos Compartidos - Top 5', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Fuerza de Coherencia')\n",
    "\n",
    "# Frecuencias dominantes\n",
    "economic_freqs = [f for f in spectral_analysis.dominant_frequencies if f['series'] == 'economic']\n",
    "solar_freqs = [f for f in spectral_analysis.dominant_frequencies if f['series'] == 'solar']\n",
    "\n",
    "economic_periods = [f['period_years'] for f in economic_freqs[:3]]\n",
    "economic_power = [f['power'] for f in economic_freqs[:3]]\n",
    "solar_periods = [f['period_years'] for f in solar_freqs[:3]]\n",
    "solar_power = [f['power'] for f in solar_freqs[:3]]\n",
    "\n",
    "axes[1, 1].bar(np.arange(3) - 0.2, economic_power, 0.4, label='Econ√≥mico', alpha=0.7)\n",
    "axes[1, 1].bar(np.arange(3) + 0.2, solar_power, 0.4, label='Solar', alpha=0.7)\n",
    "axes[1, 1].set_title('Frecuencias Dominantes por Dominio', fontweight='bold')\n",
    "axes[1, 1].set_xticks(np.arange(3))\n",
    "axes[1, 1].set_xticklabels([f'{p:.1f}a' for p in economic_periods])\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_ylabel('Potencia Espectral')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ An√°lisis espectral completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. An√°lisis de Causalidad con M√∫ltiples M√©todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de causalidad avanzado\n",
    "print(\"üîç Analizando causalidad con m√∫ltiples m√©todos...\")\n",
    "\n",
    "causality_analysis = await correlation_service.analyze_causality(sunspots_series, sp500_series)\n",
    "\n",
    "# Visualizar resultados de causalidad\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Granger Causality\n",
    "granger_lags = [int(k.split('_')[1]) for k in causality_analysis.granger_causality.keys() \n",
    "                if 'solar_to_economic' in k]\n",
    "granger_pvalues = [v for k, v in causality_analysis.granger_causality.items() \n",
    "                   if 'solar_to_economic' in k]\n",
    "\n",
    "axes[0].plot(granger_lags, granger_pvalues, 'o-', color='blue', label='Solar ‚Üí Econ√≥mico')\n",
    "axes[0].axhline(0.05, color='red', linestyle='--', alpha=0.7, label='Umbral 5%')\n",
    "axes[0].set_title('Causalidad de Granger', fontweight='bold')\n",
    "axes[0].set_xlabel('Lag (meses)')\n",
    "axes[0].set_ylabel('p-value')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# M√©tricas de causalidad\n",
    "causal_metrics = {\n",
    "    'Transfer Entropy': causality_analysis.transfer_entropy,\n",
    "    'Cross Mapping': causality_analysis.convergent_cross_mapping,\n",
    "    'Confianza': causality_analysis.confidence\n",
    "}\n",
    "\n",
    "axes[1].bar(causal_metrics.keys(), causal_metrics.values(), color=['orange', 'green', 'purple'])\n",
    "axes[1].set_title('M√©tricas de Causalidad', fontweight='bold')\n",
    "axes[1].set_ylabel('Valor')\n",
    "for i, v in enumerate(causal_metrics.values()):\n",
    "    axes[1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Direcci√≥n de causalidad\n",
    "direction = causality_analysis.direction\n",
    "confidence = causality_analysis.confidence\n",
    "\n",
    "directions = ['Solar‚ÜíEcon', 'Econ‚ÜíSolar', 'Bidireccional', 'Ninguna']\n",
    "values = [0.25, 0.25, 0.25, 0.25]  # Placeholder\n",
    "\n",
    "if direction == 'solar_to_economic':\n",
    "    values = [confidence, 0.1, 0.05, 1-confidence-0.15]\n",
    "elif direction == 'economic_to_solar':\n",
    "    values = [0.1, confidence, 0.05, 1-confidence-0.15]\n",
    "elif direction == 'bidirectional':\n",
    "    values = [0.3, 0.3, confidence, 1-confidence-0.6]\n",
    "else:\n",
    "    values = [0.1, 0.1, 0.1, 0.7]\n",
    "\n",
    "colors = ['lightcoral', 'lightblue', 'lightgreen', 'lightgray']\n",
    "axes[2].pie(values, labels=directions, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "axes[2].set_title('Direcci√≥n de Causalidad', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üéØ Direcci√≥n de causalidad: {causality_analysis.direction}\")\n",
    "print(f\"üìä Confianza: {causality_analysis.confidence:.3f}\")\n",
    "print(f\"üîó Relaci√≥n: {causality_analysis.cause} ‚Üí {causality_analysis.effect}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An√°lisis Wavelet para Detecci√≥n de Ciclos Multi-Escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis wavelet para detecci√≥n multi-escala\n",
    "print(\"üåä Realizando an√°lisis wavelet...\")\n",
    "\n",
    "def wavelet_analysis(series, title):\n",
    "    \"\"\"An√°lisis wavelet completo de una serie\"\"\"\n",
    "    # Limpiar datos\n",
    "    series_clean = series.dropna()\n",
    "    data = series_clean.values\n",
    "    \n",
    "    # Configurar wavelets\n",
    "    scales = np.arange(1, 128)\n",
    "    wavelet = 'cmor1.5-1.0'\n",
    "    \n",
    "    # Calcular coeficientes wavelet\n",
    "    coefficients, frequencies = pywt.cwt(data, scales, wavelet)\n",
    "    \n",
    "    # Crear visualizaci√≥n\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8))\n",
    "    \n",
    "    # Serie temporal\n",
    "    ax1.plot(series_clean.index, data, color='black', linewidth=1)\n",
    "    ax1.set_title(f'{title} - Serie Temporal', fontweight='bold')\n",
    "    ax1.set_ylabel('Valor')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Escalograma\n",
    "    im = ax2.imshow(np.abs(coefficients), extent=[0, len(data), scales[-1], scales[1]], \n",
    "                   aspect='auto', cmap='jet', interpolation='bilinear')\n",
    "    ax2.set_title(f'{title} - Escalograma Wavelet', fontweight='bold')\n",
    "    ax2.set_xlabel('Tiempo')\n",
    "    ax2.set_ylabel('Escala')\n",
    "    plt.colorbar(im, ax=ax2, label='Amplitud')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return coefficients, frequencies\n",
    "\n",
    "# An√°lisis wavelet para series solares y econ√≥micas\n",
    "if len(sunspots_series) > 100:\n",
    "    sunspots_coeff, sunspots_freq = wavelet_analysis(sunspots_series, 'Manchas Solares')\n",
    "\n",
    "if len(sp500_series) > 100:\n",
    "    sp500_coeff, sp500_freq = wavelet_analysis(sp500_series, 'S&P 500')\n",
    "\n",
    "print(\"‚úÖ An√°lisis wavelet completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Correlaci√≥n No Lineal con Informaci√≥n Mutua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de correlaci√≥n no lineal\n",
    "print(\"üîÑ Calculando correlaciones no lineales...\")\n",
    "\n",
    "# Alinear series\n",
    "common_dates = sunspots_series.index.intersection(sp500_series.index)\n",
    "sunspots_aligned = sunspots_series.loc[common_dates]\n",
    "sp500_aligned = sp500_series.loc[common_dates]\n",
    "\n",
    "# Calcular m√∫ltiples medidas de correlaci√≥n\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "\n",
    "correlation_measures = {}\n",
    "\n",
    # Pearson (lineal)\n",
    "corr_pearson, p_pearson = pearsonr(sunspots_aligned, sp500_aligned)\n",
    "correlation_measures['Pearson'] = corr_pearson\n",
    "\n",
    "# Spearman (monot√≥nica)\n",
    "corr_spearman, p_spearman = spearmanr(sunspots_aligned, sp500_aligned)\n",
    "correlation_measures['Spearman'] = corr_spearman\n",
    "\n",
    "# Kendall (ordinal)\n",
    "corr_kendall, p_kendall = kendalltau(sunspots_aligned, sp500_aligned)\n",
    "correlation_measures['Kendall'] = corr_kendall\n",
    "\n",
    "# Informaci√≥n Mutua (no lineal)\n",
    "def calc_mutual_info(x, y, bins=20):\n",
    "    \"\"\"Calcular informaci√≥n mutua entre dos variables\"\"\"\n",
    "    c_xy = np.histogram2d(x, y, bins)[0]\n",
    "    mi = mutual_info_score(None, None, contingency=c_xy)\n",
    "    return mi\n",
    "\n",
    "mi_score = calc_mutual_info(sunspots_aligned, sp500_aligned)\n",
    "correlation_measures['Mutual Info'] = mi_score\n",
    "\n",
    "# Visualizar comparaci√≥n\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    # Scatter plot con densidad\n",
    "sc = ax1.scatter(sunspots_aligned, sp500_aligned, \n",
    "                c=range(len(sunspots_aligned)), cmap='viridis', alpha=0.6)\n",
    "ax1.set_xlabel('Manchas Solares')\n",
    "ax1.set_ylabel('S&P 500')\n",
    "ax1.set_title('Diagrama de Dispersi√≥n: Solar vs Econ√≥mico', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "plt.colorbar(sc, ax=ax1, label='Tiempo')\n",
    "\n",
    # Comparaci√≥n de medidas de correlaci√≥n\n",
    "measures = list(correlation_measures.keys())\n",
    "values = list(correlation_measures.values())\n",
    "colors = ['blue', 'green', 'orange', 'red']\n",
    "\n",
    "bars = ax2.bar(measures, values, color=colors, alpha=0.7)\n",
    "ax2.set_title('Comparaci√≥n de Medidas de Correlaci√≥n', fontweight='bold')\n",
    "ax2.set_ylabel('Valor de Correlaci√≥n')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    # A√±adir valores en las barras\n",
    "for bar, value in zip(bars, values):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Resumen de Correlaciones:\")\n",
    "for measure, value in correlation_measures.items():\n",
    "    print(f\"  - {measure}: {value:.4f}\")\n",
    "\n",
    "# An√°lisis de no-linealidad\n",
    "if abs(correlation_measures['Mutual Info']) > abs(correlation_measures['Pearson']) * 1.5:\n",
    "    print(\"\\nüîç HALLAZGO: Posible relaci√≥n no lineal detectada\")\n",
    "    print(\"   La informaci√≥n mutua sugiere dependencias no capturadas por correlaci√≥n lineal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. An√°lisis de Ciclos Comunes y Sincronizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificaci√≥n de ciclos comunes\n",
    "print(\"üîÑ Identificando ciclos comunes...\")\n",
    "\n",
    "common_cycles = correlation_service.find_common_cycles()\n",
    "\n",
    "# Visualizar ciclos de alta confianza\n",
    "high_conf_cycles = common_cycles['high_confidence_cycles']\n",
    "medium_conf_cycles = common_cycles['medium_confidence_cycles']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    # Ciclos de alta confianza\n",
    "if high_conf_cycles:\n",
    "    names = [cycle['name'] for cycle in high_conf_cycles]\n",
    "    periods = [cycle['period'] for cycle in high_conf_cycles]\n",
    "    strengths = [cycle['strength'] for cycle in high_conf_cycles]\n",
    "    \n",
    "    bars = axes[0].barh(names, strengths, color='lightgreen', alpha=0.7)\n",
    "    axes[0].set_title('Ciclos de Alta Confianza', fontweight='bold')\n",
    "    axes[0].set_xlabel('Fuerza de Correlaci√≥n')\n",
    "    \n",
    "    for bar, period in zip(bars, periods):\n",
    "        axes[0].text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{period}a', va='center')\n",
    "\n",
    # Ciclos de media confianza\n",
    "if medium_conf_cycles:\n",
    "    names = [cycle['name'] for cycle in medium_conf_cycles]\n",
    "    periods = [cycle['period'] for cycle in medium_conf_cycles]\n",
    "    strengths = [cycle['strength'] for cycle in medium_conf_cycles]\n",
    "    \n",
    "    bars = axes[1].barh(names, strengths, color='lightblue', alpha=0.7)\n",
    "    axes[1].set_title('Ciclos de Media Confianza', fontweight='bold')\n",
    "    axes[1].set_xlabel('Fuerza de Correlaci√≥n')\n",
    "    \n",
    "    for bar, period in zip(bars, periods):\n",
    "        axes[1].text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{period}a', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Relaciones entre ciclos\n",
    "print(\"\\nüîó Relaciones entre Ciclos:\")\n",
    "for relationship in common_cycles['cycle_relationships']:\n",
    "    print(f\"  - {relationship['relationship']}\")\n",
    "    print(f\"    Ratio: {relationship['ratio']:.3f}, Desviaci√≥n: {relationship['deviation']:.3f}\")\n",
    "    print(f\"    Significancia: {relationship['significance']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusiones del An√°lisis de Correlaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ CONCLUSIONES DEL AN√ÅLISIS DE CORRELACI√ìN DE CICLOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Resumen ejecutivo\n",
    "print(\"\\nüìä RESUMEN EJECUTIVO:\")\n",
    "print(f\"‚Ä¢ Correlaci√≥n lineal (Pearson): {correlation_measures['Pearson']:.3f}\")\n",
    "print(f\"‚Ä¢ Correlaci√≥n no lineal (Mutual Info): {correlation_measures['Mutual Info']:.3f}\")\n",
    "print(f\"‚Ä¢ Direcci√≥n de causalidad: {causality_analysis.direction}\")\n",
    "print(f\"‚Ä¢ Confianza causal: {causality_analysis.confidence:.1%}\")\n",
    "print(f\"‚Ä¢ Ciclos comunes identificados: {len(common_cycles['high_confidence_cycles']) + len(common_cycles['medium_confidence_cycles'])}\")\n",
    "\n",
    "# Hallazgos clave\n",
    "print(\"\\nüîç HALLAZGOS CLAVE:\")\n",
    "\n",
    "hallazgos = []\n",
    "\n",
    # Hallazgo 1: Fuerza de correlaci√≥n\n",
    "if abs(correlation_measures['Pearson']) > 0.3:\n",
    "    hallazgos.append(\"‚Ä¢ Correlaci√≥n lineal significativa detectada\")\n",
    "else:\n",
    "    hallazgos.append(\"‚Ä¢ Correlaci√≥n lineal d√©bil o no significativa\")\n",
    "\n",
    # Hallazgo 2: No-linealidad\n",
    "if correlation_measures['Mutual Info'] > correlation_measures['Pearson'] * 1.2:\n",
    "    hallazgos.append(\"‚Ä¢ Evidencia de relaciones no lineales importantes\")\n",
    "\n",
    # Hallazgo 3: Causalidad\n",
    "if causality_analysis.confidence > 0.7:\n",
    "    hallazgos.append(f\"‚Ä¢ Causalidad {causality_analysis.direction} con alta confianza\")\n",
    "elif causality_analysis.confidence > 0.5:\n",
    "    hallazgos.append(f\"‚Ä¢ Causalidad {causality_analysis.direction} con confianza moderada\")\n",
    "else:\n",
    "    hallazgos.append(\"‚Ä¢ Causalidad no concluyente\")\n",
    "\n",
    # Hallazgo 4: Ciclos\n",
    "if high_conf_cycles:\n",
    "    hallazgos.append(f\"‚Ä¢ {len(high_conf_cycles)} ciclo(s) de alta confianza identificado(s)\")\n",
    "\n",
    # Hallazgo 5: Sincronizaci√≥n\n",
    "sync_analysis = common_cycles['synchronization_analysis']\n",
    "if sync_analysis:\n",
    "    avg_sync = np.mean([s.synchronization_strength for s in sync_analysis])\n",
    "    hallazgos.append(f\"‚Ä¢ Sincronizaci√≥n promedio: {avg_sync:.1%}\")\n",
    "\n",
    "print(\"\\n\".join(hallazgos))\n",
    "\n",
    "# Implicaciones\n",
    "print(\"\\nüí° IMPLICACIONES PARA LA INVESTIGACI√ìN:\")\n",
    "implicaciones = [\n",
    "    \"‚Ä¢ Validaci√≥n parcial de las teor√≠as de Chizhevsky sobre influencia solar\",\n",
    "    \"‚Ä¢ Necesidad de considerar relaciones no lineales en modelos predictivos\", \n",
    "    \"‚Ä¢ Importancia del an√°lisis multi-escala para capturar ciclos complejos\",\n",
    "    \"‚Ä¢ Potencial para sistemas de alerta temprana basados en ciclos solares\",\n",
    "    \"‚Ä¢ Base cient√≠fica para estrategias de inversi√≥n solar-influenciadas\"\n",
    "]\n",
    "print(\"\\n\".join(implicaciones))\n",
    "\n",
    "print(f\"\\nüìÖ An√°lisis generado: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(\"üî¨ HelioBio-Economic v1.0 - An√°lisis de Correlaci√≥n Avanzado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
